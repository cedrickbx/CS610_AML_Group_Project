{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: torch in d:\\anaconda3\\lib\\site-packages (2.7.0+cu126)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda3\\lib\\site-packages (0.22.0+cu126)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\anaconda3\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda3\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import tqdm\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running On CPU, Please skip this cell\n",
    "import cuml\n",
    "print(cuml.__version__)\n",
    "from cuml.model_selection import train_test_split\n",
    "from cuml.metrics import accuracy_score\n",
    "%load_ext cuml.accel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning: datasource\n",
      "adidas_forum_high: 150 images\n",
      "adidas_forum_low: 115 images\n",
      "adidas_gazelle: 149 images\n",
      "adidas_nmd_r1: 115 images\n",
      "adidas_samba: 115 images\n",
      "adidas_stan_smith: 147 images\n",
      "adidas_superstar: 114 images\n",
      "adidas_ultraboost: 150 images\n",
      "asics_gel-lyte_iii: 91 images\n",
      "converse_chuck_70_high: 115 images\n",
      "converse_chuck_70_low: 148 images\n",
      "converse_chuck_taylor_all-star_high: 114 images\n",
      "converse_chuck_taylor_all-star_low: 114 images\n",
      "converse_one_star: 150 images\n",
      "new_balance_327: 108 images\n",
      "new_balance_550: 150 images\n",
      "new_balance_574: 150 images\n",
      "new_balance_990: 113 images\n",
      "new_balance_992: 150 images\n",
      "nike_air_force_1_high: 115 images\n",
      "nike_air_force_1_low: 147 images\n",
      "nike_air_force_1_mid: 148 images\n",
      "nike_air_jordan_11: 113 images\n",
      "nike_air_jordan_1_high: 114 images\n",
      "nike_air_jordan_1_low: 115 images\n",
      "nike_air_jordan_3: 100 images\n",
      "nike_air_jordan_4: 150 images\n",
      "nike_air_max_1: 106 images\n",
      "nike_air_max_270: 149 images\n",
      "nike_air_max_90: 150 images\n",
      "nike_air_max_95: 115 images\n",
      "nike_air_max_97: 115 images\n",
      "nike_air_max_plus_(tn): 115 images\n",
      "nike_air_vapormax_flyknit: 149 images\n",
      "nike_air_vapormax_plus: 107 images\n",
      "nike_blazer_mid_77: 115 images\n",
      "nike_cortez: 150 images\n",
      "nike_dunk_high: 150 images\n",
      "nike_dunk_low: 115 images\n",
      "puma_suede_classic: 148 images\n",
      "reebok_classic_leather: 115 images\n",
      "reebok_club_c_85: 148 images\n",
      "salomon_xt-6: 147 images\n",
      "vans_authentic: 148 images\n",
      "vans_old_skool: 113 images\n",
      "vans_sk8-hi: 149 images\n",
      "vans_slip-on_checkerboard: 115 images\n",
      "yeezy_700_wave_runner: 108 images\n",
      "yeezy_boost_350_v2: 148 images\n",
      "yeezy_slide: 145 images\n"
     ]
    }
   ],
   "source": [
    "def count_images(datasource_path):\n",
    "    image_counts = {}\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}\n",
    "\n",
    "    if not os.path.isdir(datasource_path):\n",
    "        print(f\"Error: Path '{datasource_path}' is not a directory.\")\n",
    "        return image_counts\n",
    "\n",
    "    for subfolder_name in os.listdir(datasource_path):\n",
    "        subfolder_path = os.path.join(datasource_path, subfolder_name)\n",
    "\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            count = 0\n",
    "            for file_name in os.listdir(subfolder_path):\n",
    "                file_path = os.path.join(subfolder_path, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    _, ext = os.path.splitext(file_name)\n",
    "                    if ext.lower() in image_extensions:\n",
    "                        count += 1\n",
    "            image_counts[subfolder_name] = count\n",
    "    return image_counts\n",
    "\n",
    "image_dir = 'datasource'\n",
    "print(f\"Scanning: {image_dir}\")\n",
    "counts = count_images(image_dir)\n",
    "\n",
    "if counts:\n",
    "    for folder, count in counts.items():\n",
    "        print(f\"{folder}: {count} images\")\n",
    "else:\n",
    "    print(\"No images found or path is incorrect/empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images\n",
    "def resize_image_in_folder(input_dir, output_dir, size=(224, 224), desc='resizing images'):\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory {input_dir} does not exist. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    supported_formats = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(supported_formats):\n",
    "            img_input_path = os.path.join(input_dir, filename)\n",
    "            img_output_path = os.path.join(output_dir, filename)\n",
    "            try:\n",
    "                img = cv2.imread(img_input_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "                if img is None:\n",
    "                    print(f\"Error loading {img_input_path}\")\n",
    "                    continue\n",
    "                resized_img = cv2.resize(img, size, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "                if img_output_path.lower().endswith(('.jpg', '.jpeg')) and resized_img.shape[-1] == 4:\n",
    "                    resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGRA2BGR)\n",
    "                cv2.imwrite(img_output_path, resized_img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_input_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all folders\n",
    "def batch_resize_images(base_input_dir, base_output_dir, size=(128, 128)):\n",
    "    if not os.path.exists(base_input_dir):\n",
    "        print(f\"Base directory {base_input_dir} does not exist. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(base_output_dir, exist_ok=True) # if output directory does not exist, create it.\n",
    "\n",
    "    for folder in tqdm.tqdm(os.listdir(base_input_dir)):\n",
    "        current_input_subfolder = os.path.join(base_input_dir, folder)\n",
    "        current_output_subfolder = os.path.join(base_output_dir, folder)\n",
    "\n",
    "        if os.path.isdir(current_input_subfolder):\n",
    "            resize_image_in_folder(current_input_subfolder, current_output_subfolder, size=size)\n",
    "        else:\n",
    "            print(f\"Skipping {current_input_subfolder} as it is not a directory.\")\n",
    "\n",
    "    print(\"Batch resizing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:47<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch resizing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dir = '../CS610_AML_Group_Project/datasource'\n",
    "output_dir = '../CS610_AML_Group_Project/resized_images'\n",
    "batch_resize_images(input_dir, output_dir, size=(128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gray Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_image_in_folder(input_dir, output_dir):\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory {input_dir} does not exist. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    supported_formats = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(supported_formats):\n",
    "            img_input_path = os.path.join(input_dir, filename)\n",
    "            img_output_path = os.path.join(output_dir, filename)\n",
    "            try:\n",
    "                img = cv2.imread(img_input_path)\n",
    "                if img is None:\n",
    "                    print(f\"Error loading {img_input_path}\")\n",
    "                    continue\n",
    "                # Convert to grayscale\n",
    "                gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                cv2.imwrite(img_output_path, gray_img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_input_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_grayscale_images(base_input_dir, base_output_dir):\n",
    "    if not os.path.exists(base_input_dir):\n",
    "        print(f\"Base directory {base_input_dir} does not exist. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "    for folder in tqdm.tqdm(os.listdir(base_input_dir)):\n",
    "        current_input_subfolder = os.path.join(base_input_dir, folder)\n",
    "        current_output_subfolder = os.path.join(base_output_dir, folder)\n",
    "\n",
    "        if os.path.isdir(current_input_subfolder):\n",
    "            grayscale_image_in_folder(current_input_subfolder, current_output_subfolder)\n",
    "        else:\n",
    "            print(f\"Skipping {current_input_subfolder} as it is not a directory.\")\n",
    "\n",
    "    print(\"Batch grayscale completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:29<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch grayscale completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_input_dir = '../CS610_AML_Group_Project/resized_images'\n",
    "base_output_dir = '../CS610_AML_Group_Project/grayscale_images'\n",
    "batch_grayscale_images(base_input_dir, base_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_df(data_dir):\n",
    "    \"\"\"\n",
    "    Create a DataFrame with image paths and their corresponding class labels\n",
    "    \"\"\"\n",
    "    image_data = []\n",
    "    \n",
    "    # Walk through all subdirectories in the data directory\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        \n",
    "        # Skip if not a directory\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "            \n",
    "        # Get all image files in the class directory\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(class_path, filename)\n",
    "                image_data.append({\n",
    "                    'image_path': image_path,\n",
    "                    'class': class_name\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(image_data)\n",
    "\n",
    "def split_dataset(data_dir, output_dir, test_size=0.2, val_size=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the dataset into training, validation, and test sets\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the original dataset\n",
    "        output_dir: Directory to save the split datasets\n",
    "        test_size: Proportion of data for test set (default: 0.2)\n",
    "        val_size: Proportion of remaining data for validation set (default: 0.2)\n",
    "        random_state: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Creating dataset DataFrame...\")\n",
    "    df = image_to_df(data_dir)\n",
    "    \n",
    "    print(f\"Total images found: {len(df)}\")\n",
    "    print(f\"Number of classes: {df['class'].nunique()}\")\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(df['class'].value_counts())\n",
    "    \n",
    "    # Encode class labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['encoded_class'] = label_encoder.fit_transform(df['class'])\n",
    "    \n",
    "    # Display class mapping\n",
    "    print(\"\\nClass to encoded label mapping:\")\n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        print(f\"{class_name}: {i}\")\n",
    "    \n",
    "    # First split: separate test set\n",
    "    train_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=df['encoded_class']\n",
    "    )\n",
    "    \n",
    "    # Create output directories\n",
    "    train_dir = os.path.join(output_dir, 'train')\n",
    "    test_dir = os.path.join(output_dir, 'test')\n",
    "    \n",
    "    for dir_path in [train_dir, test_dir]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    print(\"\\nCopying files to split directories...\")\n",
    "    \n",
    "    # Copy training files\n",
    "    print(\"Copying training files...\")\n",
    "    for _, row in tqdm.tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "        class_dir = os.path.join(train_dir, row['class'])\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        \n",
    "        filename = os.path.basename(row['image_path'])\n",
    "        dest_path = os.path.join(class_dir, filename)\n",
    "        shutil.copy2(row['image_path'], dest_path)\n",
    "    \n",
    "    # Copy test files\n",
    "    print(\"Copying test files...\")\n",
    "    for _, row in tqdm.tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "        class_dir = os.path.join(test_dir, row['class'])\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        \n",
    "        filename = os.path.basename(row['image_path'])\n",
    "        dest_path = os.path.join(class_dir, filename)\n",
    "        shutil.copy2(row['image_path'], dest_path)\n",
    "    \n",
    "    # Save split information\n",
    "    split_info = {\n",
    "        'total_images': len(df),\n",
    "        'train_images': len(train_df),\n",
    "        'test_images': len(test_df),\n",
    "        'num_classes': len(label_encoder.classes_),\n",
    "        'class_mapping': dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "    }\n",
    "    \n",
    "    # Save DataFrames\n",
    "    train_df.to_csv(os.path.join(output_dir, 'train_split.csv'), index=False)\n",
    "    test_df.to_csv(os.path.join(output_dir, 'test_split.csv'), index=False)\n",
    "    \n",
    "    # Save split information\n",
    "    split_info_df = pd.DataFrame([split_info])\n",
    "    split_info_df.to_csv(os.path.join(output_dir, 'split_info.csv'), index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATASET SPLIT SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total images: {len(df)}\")\n",
    "    print(f\"Training set: {len(train_df)} images ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Test set: {len(test_df)} images ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Number of classes: {len(label_encoder.classes_)}\")\n",
    "    print(f\"\\nSplit datasets saved to: {output_dir}\")\n",
    "    \n",
    "    return train_df, test_df, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset DataFrame...\n",
      "Total images found: 6480\n",
      "Number of classes: 50\n",
      "\n",
      "Class distribution:\n",
      "class\n",
      "adidas_forum_high                      150\n",
      "nike_air_jordan_4                      150\n",
      "nike_air_max_90                        150\n",
      "new_balance_992                        150\n",
      "new_balance_574                        150\n",
      "new_balance_550                        150\n",
      "adidas_ultraboost                      150\n",
      "nike_cortez                            150\n",
      "converse_one_star                      150\n",
      "nike_dunk_high                         150\n",
      "nike_air_vapormax_flyknit              149\n",
      "nike_air_max_270                       149\n",
      "vans_sk8-hi                            149\n",
      "adidas_gazelle                         149\n",
      "converse_chuck_70_low                  148\n",
      "reebok_club_c_85                       148\n",
      "vans_authentic                         148\n",
      "yeezy_boost_350_v2                     148\n",
      "nike_air_force_1_mid                   148\n",
      "puma_suede_classic                     148\n",
      "salomon_xt-6                           147\n",
      "adidas_stan_smith                      147\n",
      "nike_air_force_1_low                   147\n",
      "yeezy_slide                            145\n",
      "nike_air_jordan_1_low                  115\n",
      "adidas_nmd_r1                          115\n",
      "vans_slip-on_checkerboard              115\n",
      "adidas_samba                           115\n",
      "nike_air_force_1_high                  115\n",
      "nike_air_max_95                        115\n",
      "nike_air_max_97                        115\n",
      "nike_air_max_plus_(tn)                 115\n",
      "converse_chuck_70_high                 115\n",
      "nike_blazer_mid_77                     115\n",
      "reebok_classic_leather                 115\n",
      "adidas_forum_low                       115\n",
      "nike_dunk_low                          115\n",
      "converse_chuck_taylor_all-star_high    114\n",
      "adidas_superstar                       114\n",
      "converse_chuck_taylor_all-star_low     114\n",
      "nike_air_jordan_1_high                 114\n",
      "new_balance_990                        113\n",
      "vans_old_skool                         113\n",
      "nike_air_jordan_11                     113\n",
      "new_balance_327                        108\n",
      "yeezy_700_wave_runner                  108\n",
      "nike_air_vapormax_plus                 107\n",
      "nike_air_max_1                         106\n",
      "nike_air_jordan_3                      100\n",
      "asics_gel-lyte_iii                      91\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class to encoded label mapping:\n",
      "adidas_forum_high: 0\n",
      "adidas_forum_low: 1\n",
      "adidas_gazelle: 2\n",
      "adidas_nmd_r1: 3\n",
      "adidas_samba: 4\n",
      "adidas_stan_smith: 5\n",
      "adidas_superstar: 6\n",
      "adidas_ultraboost: 7\n",
      "asics_gel-lyte_iii: 8\n",
      "converse_chuck_70_high: 9\n",
      "converse_chuck_70_low: 10\n",
      "converse_chuck_taylor_all-star_high: 11\n",
      "converse_chuck_taylor_all-star_low: 12\n",
      "converse_one_star: 13\n",
      "new_balance_327: 14\n",
      "new_balance_550: 15\n",
      "new_balance_574: 16\n",
      "new_balance_990: 17\n",
      "new_balance_992: 18\n",
      "nike_air_force_1_high: 19\n",
      "nike_air_force_1_low: 20\n",
      "nike_air_force_1_mid: 21\n",
      "nike_air_jordan_11: 22\n",
      "nike_air_jordan_1_high: 23\n",
      "nike_air_jordan_1_low: 24\n",
      "nike_air_jordan_3: 25\n",
      "nike_air_jordan_4: 26\n",
      "nike_air_max_1: 27\n",
      "nike_air_max_270: 28\n",
      "nike_air_max_90: 29\n",
      "nike_air_max_95: 30\n",
      "nike_air_max_97: 31\n",
      "nike_air_max_plus_(tn): 32\n",
      "nike_air_vapormax_flyknit: 33\n",
      "nike_air_vapormax_plus: 34\n",
      "nike_blazer_mid_77: 35\n",
      "nike_cortez: 36\n",
      "nike_dunk_high: 37\n",
      "nike_dunk_low: 38\n",
      "puma_suede_classic: 39\n",
      "reebok_classic_leather: 40\n",
      "reebok_club_c_85: 41\n",
      "salomon_xt-6: 42\n",
      "vans_authentic: 43\n",
      "vans_old_skool: 44\n",
      "vans_sk8-hi: 45\n",
      "vans_slip-on_checkerboard: 46\n",
      "yeezy_700_wave_runner: 47\n",
      "yeezy_boost_350_v2: 48\n",
      "yeezy_slide: 49\n",
      "\n",
      "Copying files to split directories...\n",
      "Copying training files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5184/5184 [00:03<00:00, 1614.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying test files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [00:00<00:00, 1657.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DATASET SPLIT SUMMARY\n",
      "==================================================\n",
      "Total images: 6480\n",
      "Training set: 5184 images (80.0%)\n",
      "Test set: 1296 images (20.0%)\n",
      "Number of classes: 50\n",
      "\n",
      "Split datasets saved to: ../CS610_AML_Group_Project/split_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                             image_path  \\\n",
       " 6177  ../CS610_AML_Group_Project/grayscale_images\\ye...   \n",
       " 288   ../CS610_AML_Group_Project/grayscale_images\\ad...   \n",
       " 6340  ../CS610_AML_Group_Project/grayscale_images\\ye...   \n",
       " 3096  ../CS610_AML_Group_Project/grayscale_images\\ni...   \n",
       " 3640  ../CS610_AML_Group_Project/grayscale_images\\ni...   \n",
       " ...                                                 ...   \n",
       " 2769  ../CS610_AML_Group_Project/grayscale_images\\ni...   \n",
       " 5597  ../CS610_AML_Group_Project/grayscale_images\\va...   \n",
       " 5385  ../CS610_AML_Group_Project/grayscale_images\\re...   \n",
       " 4353  ../CS610_AML_Group_Project/grayscale_images\\ni...   \n",
       " 1725  ../CS610_AML_Group_Project/grayscale_images\\co...   \n",
       " \n",
       "                           class  encoded_class  \n",
       " 6177      yeezy_700_wave_runner             47  \n",
       " 288              adidas_gazelle              2  \n",
       " 6340                yeezy_slide             49  \n",
       " 3096      nike_air_jordan_1_low             24  \n",
       " 3640           nike_air_max_270             28  \n",
       " ...                         ...            ...  \n",
       " 2769       nike_air_force_1_mid             21  \n",
       " 5597             vans_authentic             43  \n",
       " 5385           reebok_club_c_85             41  \n",
       " 4353  nike_air_vapormax_flyknit             33  \n",
       " 1725          converse_one_star             13  \n",
       " \n",
       " [5184 rows x 3 columns],\n",
       "                                              image_path  \\\n",
       " 4337  ../CS610_AML_Group_Project/grayscale_images\\ni...   \n",
       " 2029  ../CS610_AML_Group_Project/grayscale_images\\ne...   \n",
       " 5465  ../CS610_AML_Group_Project/grayscale_images\\sa...   \n",
       " 541   ../CS610_AML_Group_Project/grayscale_images\\ad...   \n",
       " 6358  ../CS610_AML_Group_Project/grayscale_images\\ye...   \n",
       " ...                                                 ...   \n",
       " 5090  ../CS610_AML_Group_Project/grayscale_images\\pu...   \n",
       " 5292  ../CS610_AML_Group_Project/grayscale_images\\re...   \n",
       " 1233  ../CS610_AML_Group_Project/grayscale_images\\co...   \n",
       " 3977  ../CS610_AML_Group_Project/grayscale_images\\ni...   \n",
       " 1706  ../CS610_AML_Group_Project/grayscale_images\\co...   \n",
       " \n",
       "                           class  encoded_class  \n",
       " 4337  nike_air_vapormax_flyknit             33  \n",
       " 2029            new_balance_550             15  \n",
       " 5465               salomon_xt-6             42  \n",
       " 541                adidas_samba              4  \n",
       " 6358                yeezy_slide             49  \n",
       " ...                         ...            ...  \n",
       " 5090         puma_suede_classic             39  \n",
       " 5292           reebok_club_c_85             41  \n",
       " 1233     converse_chuck_70_high              9  \n",
       " 3977            nike_air_max_95             30  \n",
       " 1706          converse_one_star             13  \n",
       " \n",
       " [1296 rows x 3 columns],\n",
       " LabelEncoder())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../CS610_AML_Group_Project/grayscale_images'\n",
    "out_dir = '../CS610_AML_Group_Project/split_images'\n",
    "split_dataset(data_dir, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation(image, augmentation_type,angle_range=(-15, 15), brightness_range=(0.7, 1.3)):\n",
    "    if augmentation_type == 'flip':\n",
    "        return cv2.flip(image, 1)\n",
    "    elif augmentation_type == 'rotate':\n",
    "        angle = np.random.randint(angle_range[0], angle_range[1] + 1)\n",
    "        (h, w) = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        return cv2.warpAffine(image, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "    elif augmentation_type == 'brightness':\n",
    "        brightness_factor = np.random.uniform(brightness_range[0], brightness_range[1])\n",
    "        return np.clip(image * brightness_factor, 0, 255).astype(np.uint8)\n",
    "    return image # return orginal image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Image Augmentation Starts ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting: 100%|██████████| 50/50 [01:16<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Image Augmentation Starts ======\n",
      "We have now 20736 images for modelling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>augmented_train_images\\adidas_forum_high\\0001_...</td>\n",
       "      <td>adidas_forum_high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>augmented_train_images\\adidas_forum_high\\0001_...</td>\n",
       "      <td>adidas_forum_high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>augmented_train_images\\adidas_forum_high\\0001_...</td>\n",
       "      <td>adidas_forum_high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>augmented_train_images\\adidas_forum_high\\0001_...</td>\n",
       "      <td>adidas_forum_high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>augmented_train_images\\adidas_forum_high\\0004_...</td>\n",
       "      <td>adidas_forum_high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20731</th>\n",
       "      <td>augmented_train_images\\yeezy_slide\\0144_bright...</td>\n",
       "      <td>yeezy_slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20732</th>\n",
       "      <td>augmented_train_images\\yeezy_slide\\0145_origin...</td>\n",
       "      <td>yeezy_slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20733</th>\n",
       "      <td>augmented_train_images\\yeezy_slide\\0145_flippe...</td>\n",
       "      <td>yeezy_slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20734</th>\n",
       "      <td>augmented_train_images\\yeezy_slide\\0145_rotate...</td>\n",
       "      <td>yeezy_slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20735</th>\n",
       "      <td>augmented_train_images\\yeezy_slide\\0145_bright...</td>\n",
       "      <td>yeezy_slide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20736 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path              label\n",
       "0      augmented_train_images\\adidas_forum_high\\0001_...  adidas_forum_high\n",
       "1      augmented_train_images\\adidas_forum_high\\0001_...  adidas_forum_high\n",
       "2      augmented_train_images\\adidas_forum_high\\0001_...  adidas_forum_high\n",
       "3      augmented_train_images\\adidas_forum_high\\0001_...  adidas_forum_high\n",
       "4      augmented_train_images\\adidas_forum_high\\0004_...  adidas_forum_high\n",
       "...                                                  ...                ...\n",
       "20731  augmented_train_images\\yeezy_slide\\0144_bright...        yeezy_slide\n",
       "20732  augmented_train_images\\yeezy_slide\\0145_origin...        yeezy_slide\n",
       "20733  augmented_train_images\\yeezy_slide\\0145_flippe...        yeezy_slide\n",
       "20734  augmented_train_images\\yeezy_slide\\0145_rotate...        yeezy_slide\n",
       "20735  augmented_train_images\\yeezy_slide\\0145_bright...        yeezy_slide\n",
       "\n",
       "[20736 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a directory to store the augmented images\n",
    "aug_dir = 'augmented_train_images'\n",
    "os.makedirs(aug_dir, exist_ok = True)\n",
    "image_dir = '../CS610_AML_Group_Project/split_images/train'\n",
    "\n",
    "all_images_paths = []\n",
    "all_images_labels = []\n",
    "\n",
    "\n",
    "\n",
    "sneaker_names_list = os.listdir(image_dir)\n",
    "print(\"====== Image Augmentation Starts ======\")\n",
    "for sneaker_name in tqdm.tqdm(sneaker_names_list, desc=\"Augmenting\"):\n",
    "    original_path = os.path.join(image_dir, sneaker_name)\n",
    "    if os.path.isdir(original_path):\n",
    "        aug_path = os.path.join(aug_dir, sneaker_name)\n",
    "        os.makedirs(aug_path, exist_ok = True)\n",
    "        \n",
    "        for image in os.listdir(original_path):\n",
    "\n",
    "            # design saved path\n",
    "            # 1. orinal\n",
    "            image_full_path = os.path.join(original_path, image)\n",
    "            original_image = cv2.imread(image_full_path)\n",
    "            if original_image is None:\n",
    "                print(f'WARNING: CANNOT READ IMAGE {image_full_path}, SKIPPED!')\n",
    "                continue\n",
    "            \n",
    "            base, ext = os.path.splitext(image)\n",
    "\n",
    "            # design saved path\n",
    "            # 1. orinal\n",
    "            image_name_original = f'{base}_original{ext}'\n",
    "            original_image_saved_path = os.path.join(aug_path,image_name_original)\n",
    "            # 2. flipped\n",
    "            image_name_flipped = f'{base}_flipped{ext}'\n",
    "            flipped_image_saved_path = os.path.join(aug_path,image_name_flipped)\n",
    "            # 3. rotated\n",
    "            image_name_rotated = f'{base}_rotated{ext}'\n",
    "            rotated_image_saved_path = os.path.join(aug_path,image_name_rotated)\n",
    "            # 4. bright\n",
    "            image_name_brightened = f'{base}_brightened{ext}'\n",
    "            brightened_image_saved_path = os.path.join(aug_path,image_name_brightened)\n",
    "\n",
    "            # augmentation operations\n",
    "            # 1. original\n",
    "            cv2.imwrite(original_image_saved_path, original_image)\n",
    "            all_images_paths.append(original_image_saved_path)\n",
    "            all_images_labels.append(sneaker_name)\n",
    "\n",
    "            # 2. flipped\n",
    "            img_flipped = image_augmentation(original_image, augmentation_type = 'flip')\n",
    "            cv2.imwrite(flipped_image_saved_path, img_flipped)\n",
    "            all_images_paths.append(flipped_image_saved_path)\n",
    "            all_images_labels.append(sneaker_name)\n",
    "\n",
    "            # 3. rotated\n",
    "            img_rotated = image_augmentation(original_image, augmentation_type = 'rotate')\n",
    "            cv2.imwrite(rotated_image_saved_path, img_rotated)\n",
    "            all_images_paths.append(rotated_image_saved_path)\n",
    "            all_images_labels.append(sneaker_name)\n",
    "\n",
    "            # 4. brightness\n",
    "            img_bright = image_augmentation(original_image, augmentation_type = 'brightness')\n",
    "            cv2.imwrite(brightened_image_saved_path, img_bright)\n",
    "            all_images_paths.append(brightened_image_saved_path)\n",
    "            all_images_labels.append(sneaker_name)\n",
    "\n",
    "print(\"====== Image Augmentation Starts ======\")\n",
    "\n",
    "image_df_augmented = pd.DataFrame({\n",
    "    'path': all_images_paths,\n",
    "    'label': all_images_labels\n",
    "})\n",
    "\n",
    "print(f\"We have now {len(image_df_augmented)} images for modelling\")\n",
    "\n",
    "image_df_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Models using Feature Extraction Method 1 - By HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction by HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features_recursive(input_dir, force_size = (128, 128), pixels_per_cell=(16, 16), cells_per_block=(2, 2)):\n",
    "    features = []\n",
    "    filenames = []\n",
    "    supported_formats = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp')\n",
    "    for root, dirs, files in tqdm.tqdm(os.walk(input_dir)):\n",
    "        for filename in tqdm.tqdm(files):\n",
    "            if filename.lower().endswith(supported_formats):\n",
    "                img_path = os.path.join(root, filename)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                # force resized in case feature extraction failed\n",
    "                img_resized = cv2.resize(img, force_size, interpolation=cv2.INTER_AREA)\n",
    "                # pixel normalisation\n",
    "                img_normalised = img_resized.astype(np.float32) / 255.0\n",
    "                # Extract HOG features\n",
    "                try:\n",
    "                    hog_feature = hog(img_normalised, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, feature_vector=True)\n",
    "                    features.append(hog_feature)\n",
    "                    rel_path = os.path.relpath(img_path, input_dir)\n",
    "                    filenames.append(rel_path)\n",
    "                except Exception as e:\n",
    "                    print(\"WARNING: {img_path} Failed with HOG feature extraction!\")\n",
    "                    continue\n",
    "    hogged = np.array(features)\n",
    "    return hogged, filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== HOG Extraction Starts! ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 480/480 [00:09<00:00, 50.06it/s]\n",
      "100%|██████████| 368/368 [00:08<00:00, 45.84it/s]\n",
      "100%|██████████| 476/476 [00:10<00:00, 47.13it/s]\n",
      "100%|██████████| 368/368 [00:07<00:00, 49.97it/s]\n",
      "100%|██████████| 368/368 [00:06<00:00, 53.65it/s]\n",
      "100%|██████████| 472/472 [00:08<00:00, 53.44it/s]\n",
      "100%|██████████| 364/364 [00:05<00:00, 69.42it/s]\n",
      "100%|██████████| 480/480 [00:09<00:00, 53.22it/s]\n",
      "100%|██████████| 292/292 [00:05<00:00, 52.74it/s]\n",
      "100%|██████████| 368/368 [00:06<00:00, 56.24it/s]\n",
      "100%|██████████| 472/472 [00:09<00:00, 50.76it/s]\n",
      "100%|██████████| 364/364 [00:07<00:00, 51.49it/s]\n",
      "100%|██████████| 364/364 [00:07<00:00, 51.38it/s]\n",
      "100%|██████████| 480/480 [00:07<00:00, 62.27it/s]\n",
      "100%|██████████| 348/348 [00:06<00:00, 50.87it/s]\n",
      "100%|██████████| 480/480 [00:08<00:00, 54.70it/s]\n",
      "100%|██████████| 480/480 [00:09<00:00, 51.28it/s]\n",
      "100%|██████████| 364/364 [00:07<00:00, 49.23it/s]\n",
      "100%|██████████| 480/480 [00:09<00:00, 49.68it/s]\n",
      "100%|██████████| 368/368 [00:06<00:00, 52.90it/s]\n",
      "100%|██████████| 472/472 [00:09<00:00, 52.09it/s]\n",
      "100%|██████████| 472/472 [00:09<00:00, 50.68it/s]\n",
      "100%|██████████| 360/360 [00:07<00:00, 50.90it/s]\n",
      "100%|██████████| 364/364 [00:06<00:00, 52.74it/s]\n",
      "100%|██████████| 368/368 [00:06<00:00, 53.61it/s]\n",
      "100%|██████████| 320/320 [00:05<00:00, 58.14it/s]\n",
      "100%|██████████| 480/480 [00:07<00:00, 60.47it/s]\n",
      "100%|██████████| 340/340 [00:05<00:00, 58.56it/s]\n",
      "100%|██████████| 476/476 [00:07<00:00, 64.45it/s]\n",
      "100%|██████████| 480/480 [00:07<00:00, 65.06it/s]\n",
      "100%|██████████| 368/368 [00:06<00:00, 58.93it/s]\n",
      "100%|██████████| 368/368 [00:05<00:00, 64.87it/s]\n",
      "100%|██████████| 368/368 [00:05<00:00, 62.94it/s]\n",
      "100%|██████████| 476/476 [00:07<00:00, 67.20it/s]\n",
      "100%|██████████| 344/344 [00:05<00:00, 59.18it/s]\n",
      "100%|██████████| 368/368 [00:06<00:00, 60.43it/s]\n",
      "100%|██████████| 480/480 [00:07<00:00, 60.30it/s]\n",
      "100%|██████████| 480/480 [00:07<00:00, 64.76it/s]\n",
      "100%|██████████| 368/368 [00:05<00:00, 65.79it/s]\n",
      "100%|██████████| 472/472 [00:07<00:00, 66.09it/s]\n",
      "100%|██████████| 368/368 [00:06<00:00, 61.32it/s]\n",
      "100%|██████████| 472/472 [00:07<00:00, 62.41it/s]\n",
      "100%|██████████| 472/472 [00:07<00:00, 63.69it/s]\n",
      "100%|██████████| 472/472 [00:06<00:00, 68.60it/s]\n",
      "100%|██████████| 364/364 [00:06<00:00, 60.55it/s]\n",
      "100%|██████████| 476/476 [00:07<00:00, 62.04it/s]\n",
      "100%|██████████| 368/368 [00:05<00:00, 68.30it/s]\n",
      "100%|██████████| 348/348 [00:05<00:00, 58.95it/s]\n",
      "100%|██████████| 472/472 [00:07<00:00, 62.04it/s]\n",
      "100%|██████████| 464/464 [00:06<00:00, 69.07it/s]\n",
      "51it [06:02,  7.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== HOG Extraction Completed! ======\n",
      "(20736, 1764)\n",
      "====== HOG Extraction Starts! ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 57.56it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 61.19it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 73.18it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 79.64it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 62.87it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 55.80it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 54.24it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 66.47it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 59.36it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 61.93it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 69.47it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 59.57it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 66.64it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 62.60it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 56.54it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 62.05it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 65.88it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 54.84it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 60.43it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 58.58it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 62.76it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 72.06it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 69.30it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 54.69it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 57.58it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 57.87it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 59.88it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 60.62it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 55.64it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 58.56it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 57.35it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 61.73it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 67.54it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 68.54it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 53.94it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 63.68it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 61.01it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 61.37it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 63.25it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 58.29it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 56.69it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 54.82it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 48.75it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 49.83it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 48.99it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 52.31it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 47.89it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 52.86it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 49.84it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 50.31it/s]\n",
      "51it [00:22,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== HOG Extraction Completed! ======\n",
      "(1296, 1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train set:\n",
    "input_dir = '../CS610_AML_Group_Project/augmented_train_images'\n",
    "print('====== HOG Extraction Starts! ======')\n",
    "hogged_train, filenames_train = extract_hog_features_recursive(input_dir)\n",
    "print('====== HOG Extraction Completed! ======')\n",
    "print(hogged_train.shape)  # (num_images, hog_feature_dim)\n",
    "\n",
    "# test set:\n",
    "input_dir = '../CS610_AML_Group_Project/split_images/test'\n",
    "print('====== HOG Extraction Starts! ======')\n",
    "hogged_test, filenames_test = extract_hog_features_recursive(input_dir)\n",
    "print('====== HOG Extraction Completed! ======')\n",
    "print(hogged_test.shape)  # (num_images, hog_feature_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labeling\n",
    "y_train = [f.split(os.sep)[0] for f in filenames_train]\n",
    "\n",
    "#split data into train_test split\n",
    "x_train = hogged_train.astype(np.float32)\n",
    "y_train = np.array(y_train)\n",
    "y_train, uniques = pd.factorize(y_train)\n",
    "x_train = pd.DataFrame(x_train, dtype=np.float32)\n",
    "y_train = pd.Series(y_train, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labeling\n",
    "y_test = [f.split(os.sep)[0] for f in filenames_test]\n",
    "\n",
    "#split data into train_test split\n",
    "x_test = hogged_test.astype(np.float32)\n",
    "y_test = np.array(y_test)\n",
    "y_test, uniques = pd.factorize(y_test)\n",
    "x_test = pd.DataFrame(x_test, dtype=np.float32)\n",
    "y_test = pd.Series(y_test, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Samples: 20736\n",
      "Number of Train Labels: 50\n",
      "Train Label Distribution:\n",
      "0     480\n",
      "26    480\n",
      "29    480\n",
      "18    480\n",
      "16    480\n",
      "15    480\n",
      "7     480\n",
      "36    480\n",
      "13    480\n",
      "37    480\n",
      "33    476\n",
      "28    476\n",
      "45    476\n",
      "2     476\n",
      "10    472\n",
      "41    472\n",
      "42    472\n",
      "43    472\n",
      "5     472\n",
      "48    472\n",
      "20    472\n",
      "21    472\n",
      "39    472\n",
      "49    464\n",
      "24    368\n",
      "40    368\n",
      "3     368\n",
      "46    368\n",
      "4     368\n",
      "19    368\n",
      "30    368\n",
      "31    368\n",
      "32    368\n",
      "35    368\n",
      "9     368\n",
      "1     368\n",
      "38    368\n",
      "44    364\n",
      "6     364\n",
      "12    364\n",
      "11    364\n",
      "17    364\n",
      "23    364\n",
      "22    360\n",
      "14    348\n",
      "47    348\n",
      "34    344\n",
      "27    340\n",
      "25    320\n",
      "8     292\n",
      "Name: count, dtype: int64\n",
      "Number of Test Samples: 1296\n",
      "Number of Test Labels: 50\n",
      "Test Label Distribution:\n",
      "0     30\n",
      "37    30\n",
      "28    30\n",
      "18    30\n",
      "29    30\n",
      "16    30\n",
      "15    30\n",
      "33    30\n",
      "13    30\n",
      "36    30\n",
      "10    30\n",
      "21    30\n",
      "39    30\n",
      "41    30\n",
      "7     30\n",
      "43    30\n",
      "45    30\n",
      "48    30\n",
      "2     30\n",
      "26    30\n",
      "42    29\n",
      "49    29\n",
      "20    29\n",
      "5     29\n",
      "22    23\n",
      "35    23\n",
      "3     23\n",
      "46    23\n",
      "4     23\n",
      "6     23\n",
      "40    23\n",
      "9     23\n",
      "38    23\n",
      "11    23\n",
      "23    23\n",
      "12    23\n",
      "32    23\n",
      "31    23\n",
      "30    23\n",
      "19    23\n",
      "1     23\n",
      "24    23\n",
      "17    22\n",
      "44    22\n",
      "34    21\n",
      "14    21\n",
      "27    21\n",
      "47    21\n",
      "25    20\n",
      "8     18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check if data is prepared successfully\n",
    "print(\"Number of Train Samples:\", len(y_train))\n",
    "print(\"Number of Train Labels:\", len(np.unique(y_train)))\n",
    "counts = y_train.value_counts()\n",
    "print(\"Train Label Distribution:\")\n",
    "print(counts)\n",
    "\n",
    "print(\"Number of Test Samples:\", len(y_test))\n",
    "print(\"Number of Test Labels:\", len(np.unique(y_test)))\n",
    "counts = y_test.value_counts()\n",
    "print(\"Test Label Distribution:\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Feature Standardisation Started! ======\n",
      "\n",
      "====== Feature Standardisation Completed! ======\n",
      "The Shape for Training Set after Feature Standardisation: (20736, 1764)\n",
      "The Shape for Testing Set after Feature Standardisation: (1296, 1764)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n====== Feature Standardisation Started! ======\")\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train) \n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "print(\"\\n====== Feature Standardisation Completed! ======\")\n",
    "print(f\"The Shape for Training Set after Feature Standardisation: {x_train_scaled.shape}\")\n",
    "print(f\"The Shape for Testing Set after Feature Standardisation: {x_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Dimensionality Reduction by PCA Started! ======\n",
      "\n",
      "====== Dimensionality Reduction by PCA Completed! ======\n",
      "The Shape for Training Set after Dimensionality Reduction by PCA: (20736, 241)\n",
      "The Shape for Testing Set after Dimensionality Reduction by PCA: (1296, 241)\n",
      "The Number of Chosen PCA: 241\n",
      "The Explained Variance Ratio: 0.8505\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n====== Dimensionality Reduction by PCA Started! ======\")\n",
    "pca = PCA(n_components=0.85, random_state=42) \n",
    "pca.fit(x_train_scaled)\n",
    "\n",
    "\n",
    "x_train_pca = pca.transform(x_train_scaled)\n",
    "x_test_pca = pca.transform(x_test_scaled)\n",
    "\n",
    "print(\"\\n====== Dimensionality Reduction by PCA Completed! ======\")\n",
    "print(f\"The Shape for Training Set after Dimensionality Reduction by PCA: {x_train_pca.shape}\")\n",
    "print(f\"The Shape for Testing Set after Dimensionality Reduction by PCA: {x_test_pca.shape}\")\n",
    "print(f\"The Number of Chosen PCA: {pca.n_components_}\")\n",
    "print(f\"The Explained Variance Ratio: {np.sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) RandomForestClassifier - feature extraction by hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "skip_train = False\n",
    "\n",
    "if skip_train:\n",
    "    # Import previous model\n",
    "    print(\"Training skipped, importing model trained previously...\")\n",
    "    print(\"Fitted 3 folds for each of 30 candidates, totalling 30 fits\")\n",
    "    with open('model_bank/best_hog_rf_model.pkl', 'rb') as file:\n",
    "        best_hog_rf = pickle.load(file)\n",
    "\n",
    "else:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Base model\n",
    "    base_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Hyperparameters\n",
    "    param_dist = {\n",
    "        'n_estimators': [50, 100, 150, 200],\n",
    "        'max_depth': [10, 20, 30, 40],\n",
    "        'max_features': ['sqrt', 'log2', 0.5, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    # Randomized search tuning\n",
    "    random_search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_dist,\n",
    "        n_iter=10,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        error_score='raise',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(x_train_pca, y_train)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 150, 'max_features': 0.5, 'max_depth': 40}\n",
      "Best Accuracy: 0.209008\n",
      "Total Training Time: 26.8 minutes\n"
     ]
    }
   ],
   "source": [
    "if skip_train:\n",
    "    print(\"Training skipped, printing model trained previously...\\n\")\n",
    "    print(\"Best Parameters: {'n_estimators': 150, 'max_features': 0.5, 'max_depth': 40}\")\n",
    "    print(\"Best Accuracy: 0.563416\")\n",
    "    training_time = 47.19\n",
    "else:\n",
    "    best_hog_rf = random_search.best_estimator_\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "    print(f\"Best Accuracy: {random_search.best_score_:.6f}\")\n",
    "    training_time = round(training_time /60, 2)\n",
    "print(f\"Total Training Time: {training_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Average Type</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training time (minutes)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.307099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.998950</td>\n",
       "      <td>0.328319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.307099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.999048</td>\n",
       "      <td>0.322049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.998908</td>\n",
       "      <td>0.301281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.307099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recall</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.307099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.313624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.307099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.999043</td>\n",
       "      <td>0.310891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric Average Type      Train      Test\n",
       "0   Training time (minutes)          N/A  26.800000       N/A\n",
       "1                  Accuracy          N/A   0.999035  0.307099\n",
       "2                 Precision        macro   0.998950  0.328319\n",
       "3                 Precision        micro   0.999035  0.307099\n",
       "4                 Precision     weighted   0.999048  0.322049\n",
       "5                    Recall        macro   0.998908  0.301281\n",
       "6                    Recall        micro   0.999035  0.307099\n",
       "7                    Recall     weighted   0.999035  0.307099\n",
       "8                F0.5-Score        macro   0.998939  0.313624\n",
       "9                F0.5-Score        micro   0.999035  0.307099\n",
       "10               F0.5-Score     weighted   0.999043  0.310891"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict\n",
    "y_train_pred = best_hog_rf.predict(x_train_pca)\n",
    "y_test_pred = best_hog_rf.predict(x_test_pca)\n",
    "\n",
    "# Function to save metrics\n",
    "metrics = {\"Metric\": [], \"Average Type\": [], \"Train\": [], \"Test\": []}\n",
    "def add_metric(name, avg_type, train_value, test_value):\n",
    "    metrics[\"Metric\"].append(name)\n",
    "    metrics[\"Average Type\"].append(avg_type)\n",
    "    metrics[\"Train\"].append(train_value)\n",
    "    metrics[\"Test\"].append(test_value)\n",
    "\n",
    "# Training time\n",
    "add_metric(\"Training time (minutes)\", \"N/A\", training_time, \"N/A\")\n",
    "\n",
    "# Accuracy\n",
    "add_metric(\"Accuracy\", \"N/A\",\n",
    "           accuracy_score(y_train, y_train_pred),\n",
    "           accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Precision\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Precision\", avg,\n",
    "               precision_score(y_train, y_train_pred, average=avg),\n",
    "               precision_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# Recall\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Recall\", avg,\n",
    "               recall_score(y_train, y_train_pred, average=avg),\n",
    "               recall_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# F0.5-Score \n",
    "beta = 0.5 # mis-labelled sneakers are more costly than missing labels\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(f\"F{beta}-Score\", avg,\n",
    "               fbeta_score(y_train, y_train_pred, beta=beta, average=avg),\n",
    "               fbeta_score(y_test, y_test_pred, beta=beta, average=avg))\n",
    "\n",
    "# Display metrics\n",
    "hog_rf_metrics = pd.DataFrame(metrics)\n",
    "pd.set_option('display.precision', 6)\n",
    "display(hog_rf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully ../CS610_AML_Group_Project/model_bank\\best_hog_rf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "export = True\n",
    "\n",
    "if not export:\n",
    "    print(\"Model not exported\")\n",
    "else:\n",
    "    model_bank_dir = '../CS610_AML_Group_Project/model_bank'\n",
    "    os.makedirs(model_bank_dir, exist_ok=True)\n",
    "    model_filename_pickle = 'best_hog_rf_model.pkl'\n",
    "    model_path = os.path.join(model_bank_dir, model_filename_pickle)\n",
    "    with open(model_path, 'wb') as file: \n",
    "        pickle.dump(best_hog_rf, file)\n",
    "    print(f\"Model Saved Successfully {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) KNNClassifier - feature extraction by hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "skip_train = False\n",
    "\n",
    "if skip_train:\n",
    "    # Import previous model\n",
    "    print(\"Training skipped, importing model trained previously...\")\n",
    "    print(\"Fitted 3 folds for each of 10 candidates, totalling 30 fits\")\n",
    "    with open('model_bank/best_hog_knn_model.pkl', 'rb') as file:\n",
    "        best_hog_knn = pickle.load(file)\n",
    "\n",
    "else:\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Base model\n",
    "    base_model = KNeighborsClassifier()\n",
    "\n",
    "    # Hyperparameters\n",
    "    param_dist = {\n",
    "        'n_neighbors': randint(1, 30),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'cosine']\n",
    "    }\n",
    "\n",
    "    # Randomized search tuning\n",
    "    random_search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_dist,\n",
    "        n_iter=10,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        error_score='raise',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(x_train_pca, y_train)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "Best Accuracy: 0.279900\n",
      "Total Training Time: 0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "skip_train = False\n",
    "if skip_train:\n",
    "    print(\"Training skipped, printing model trained previously...\\n\")\n",
    "    print(\"Best Parameters: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\")\n",
    "    print(\"Best Accuracy: 0.675010\")\n",
    "    training_time = 1.03\n",
    "else:\n",
    "    best_hog_knn = random_search.best_estimator_\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "    print(f\"Best Accuracy: {random_search.best_score_:.6f}\")\n",
    "    training_time = round(training_time / 60, 2)\n",
    "print(f\"Total Training Time: {training_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Average Type</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training time (minutes)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.368827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.998861</td>\n",
       "      <td>0.379593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.368827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.998971</td>\n",
       "      <td>0.385752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.998801</td>\n",
       "      <td>0.367517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.368827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recall</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.368827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>0.371319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.368827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>0.37661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric Average Type     Train      Test\n",
       "0   Training time (minutes)          N/A  0.000000       N/A\n",
       "1                  Accuracy          N/A  0.998939  0.368827\n",
       "2                 Precision        macro  0.998861  0.379593\n",
       "3                 Precision        micro  0.998939  0.368827\n",
       "4                 Precision     weighted  0.998971  0.385752\n",
       "5                    Recall        macro  0.998801  0.367517\n",
       "6                    Recall        micro  0.998939  0.368827\n",
       "7                    Recall     weighted  0.998939  0.368827\n",
       "8                F0.5-Score        macro  0.998841  0.371319\n",
       "9                F0.5-Score        micro  0.998939  0.368827\n",
       "10               F0.5-Score     weighted  0.998958   0.37661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict\n",
    "y_train_pred = best_hog_knn.predict(x_train_pca)\n",
    "y_test_pred = best_hog_knn.predict(x_test_pca)\n",
    "\n",
    "# Function to save metrics\n",
    "metrics = {\"Metric\": [], \"Average Type\": [], \"Train\": [], \"Test\": []}\n",
    "def add_metric(name, avg_type, train_value, test_value):\n",
    "    metrics[\"Metric\"].append(name)\n",
    "    metrics[\"Average Type\"].append(avg_type)\n",
    "    metrics[\"Train\"].append(train_value)\n",
    "    metrics[\"Test\"].append(test_value)\n",
    "\n",
    "# Training time\n",
    "add_metric(\"Training time (minutes)\", \"N/A\", training_time, \"N/A\")\n",
    "\n",
    "# Accuracy\n",
    "add_metric(\"Accuracy\", \"N/A\",\n",
    "           accuracy_score(y_train, y_train_pred),\n",
    "           accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Precision\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Precision\", avg,\n",
    "               precision_score(y_train, y_train_pred, average=avg),\n",
    "               precision_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# Recall\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Recall\", avg,\n",
    "               recall_score(y_train, y_train_pred, average=avg),\n",
    "               recall_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# F0.5-Score \n",
    "beta = 0.5 # mis-labelled sneakers are more costly than missing labels\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(f\"F{beta}-Score\", avg,\n",
    "               fbeta_score(y_train, y_train_pred, beta=beta, average=avg),\n",
    "               fbeta_score(y_test, y_test_pred, beta=beta, average=avg))\n",
    "\n",
    "# Display metrics\n",
    "hog_knn_metrics = pd.DataFrame(metrics)\n",
    "pd.set_option('display.precision', 6)\n",
    "display(hog_knn_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully ../CS610_AML_Group_Project/model_bank\\best_hog_knn_model.pkl\n"
     ]
    }
   ],
   "source": [
    "export = True\n",
    "\n",
    "if not export:\n",
    "    print(\"Model not exported\")\n",
    "else:\n",
    "    model_bank_dir = '../CS610_AML_Group_Project/model_bank'\n",
    "    os.makedirs(model_bank_dir, exist_ok=True)\n",
    "    model_filename_pickle = 'best_hog_knn_model.pkl'\n",
    "    model_path = os.path.join(model_bank_dir, model_filename_pickle)\n",
    "    with open(model_path, 'wb') as file: \n",
    "        pickle.dump(best_hog_knn, file)\n",
    "    print(f\"Model Saved Successfully {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) XGBoostClassifier - feature extraction by hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "skip_train = False\n",
    "\n",
    "if skip_train:\n",
    "    # Import previous model\n",
    "    print(\"Training skipped, importing model trained previously...\")\n",
    "    print(\"Fitted 3 folds for each of 10 candidates, totalling 30 fits\")\n",
    "    with open('model_bank/best_hog_xgb_model.pkl', 'rb') as file:\n",
    "        best_hog_xgb = pickle.load(file)\n",
    "\n",
    "else:\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Balance class weights\n",
    "    sample_weights = compute_sample_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        y=y_train\n",
    "    )\n",
    "\n",
    "    # Base model\n",
    "    base_model = xgb.XGBClassifier(\n",
    "        device=\"cuda\",\n",
    "        tree_method=\"hist\",\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=len(np.unique(y_train)),\n",
    "        eval_metric=['merror','mlogloss'],\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Hyperparameters\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(50, 500),\n",
    "        'max_depth': randint(3, 12),\n",
    "        'learning_rate': uniform(0.01, 0.19),  # range: 0.01 to 0.2\n",
    "        'subsample': uniform(0.7, 0.3),        # range: 0.7 to 1.0\n",
    "        'colsample_bytree': uniform(0.7, 0.3)  # range: 0.7 to 1.0\n",
    "    }\n",
    "\n",
    "    # Randomized search tuning\n",
    "    random_search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_dist,\n",
    "        n_iter=10,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        error_score='raise',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(\n",
    "        x_train_pca, y_train,\n",
    "        sample_weight = sample_weights)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.7692681476866446, 'learning_rate': 0.05579483854494223, 'max_depth': 9, 'n_estimators': 477, 'subsample': 0.848553073033381}\n",
      "Best Accuracy: 0.256028\n",
      "Total Training Time: 48.2 minutes\n"
     ]
    }
   ],
   "source": [
    "if skip_train:\n",
    "    print(\"Training skipped, printing model trained previously...\\n\")\n",
    "    print(\"Best Parameters: {'colsample_bytree': 0.7692681476866446, 'learning_rate': 0.05579483854494223, 'max_depth': 9, 'n_estimators': 477, 'subsample': 0.848553073033381}\")\n",
    "    print(\"Best Accuracy: 0.569396\")\n",
    "    training_time = 42.59\n",
    "else:\n",
    "    best_hog_xgb = random_search.best_estimator_\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "    print(f\"Best Accuracy: {random_search.best_score_:.6f}\")\n",
    "    training_time = round(training_time / 60, 2)\n",
    "print(f\"Total Training Time: {training_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Average Type</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training time (minutes)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>48.200000</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.341821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.998918</td>\n",
       "      <td>0.353889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.341821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.353453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>0.337784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.341821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recall</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.341821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.998919</td>\n",
       "      <td>0.345981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.341821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.999042</td>\n",
       "      <td>0.346817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric Average Type      Train      Test\n",
       "0   Training time (minutes)          N/A  48.200000       N/A\n",
       "1                  Accuracy          N/A   0.999035  0.341821\n",
       "2                 Precision        macro   0.998918  0.353889\n",
       "3                 Precision        micro   0.999035  0.341821\n",
       "4                 Precision     weighted   0.999046  0.353453\n",
       "5                    Recall        macro   0.998934  0.337784\n",
       "6                    Recall        micro   0.999035  0.341821\n",
       "7                    Recall     weighted   0.999035  0.341821\n",
       "8                F0.5-Score        macro   0.998919  0.345981\n",
       "9                F0.5-Score        micro   0.999035  0.341821\n",
       "10               F0.5-Score     weighted   0.999042  0.346817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict\n",
    "y_train_pred = best_hog_xgb.predict(x_train_pca)\n",
    "y_test_pred = best_hog_xgb.predict(x_test_pca)\n",
    "\n",
    "# Function to save metrics\n",
    "metrics = {\"Metric\": [], \"Average Type\": [], \"Train\": [], \"Test\": []}\n",
    "def add_metric(name, avg_type, train_value, test_value):\n",
    "    metrics[\"Metric\"].append(name)\n",
    "    metrics[\"Average Type\"].append(avg_type)\n",
    "    metrics[\"Train\"].append(train_value)\n",
    "    metrics[\"Test\"].append(test_value)\n",
    "\n",
    "# Training time\n",
    "add_metric(\"Training time (minutes)\", \"N/A\", training_time, \"N/A\")\n",
    "\n",
    "# Accuracy\n",
    "add_metric(\"Accuracy\", \"N/A\",\n",
    "           accuracy_score(y_train, y_train_pred),\n",
    "           accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Precision\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Precision\", avg,\n",
    "               precision_score(y_train, y_train_pred, average=avg),\n",
    "               precision_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# Recall\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Recall\", avg,\n",
    "               recall_score(y_train, y_train_pred, average=avg),\n",
    "               recall_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# F0.5-Score \n",
    "beta = 0.5 # mis-labelled sneakers are more costly than missing labels\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(f\"F{beta}-Score\", avg,\n",
    "               fbeta_score(y_train, y_train_pred, beta=beta, average=avg),\n",
    "               fbeta_score(y_test, y_test_pred, beta=beta, average=avg))\n",
    "\n",
    "# Display metrics\n",
    "hog_xgb_metrics = pd.DataFrame(metrics)\n",
    "pd.set_option('display.precision', 6)\n",
    "display(hog_xgb_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully ../CS610_AML_Group_Project/model_bank\\best_hog_xgb_model.pkl\n"
     ]
    }
   ],
   "source": [
    "export = True\n",
    "\n",
    "if not export:\n",
    "    print(\"Model not exported\")\n",
    "else:\n",
    "    model_bank_dir = '../CS610_AML_Group_Project/model_bank'\n",
    "    os.makedirs(model_bank_dir, exist_ok=True)\n",
    "    model_filename_pickle = 'best_hog_xgb_model.pkl'\n",
    "    model_path = os.path.join(model_bank_dir, model_filename_pickle)\n",
    "    with open(model_path, 'wb') as file: \n",
    "        pickle.dump(best_hog_xgb, file)\n",
    "    print(f\"Model Saved Successfully {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Models using Feature Extraction Method 2 - Using pretrained CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 will be used as the feature extractor due to its pre-trained weights, derived from large datasets like ImageNet, and is a popular choice to use for computer vision applications such as image classification.\n",
    "Reference:\n",
    "1) https://medium.com/@meetkalathiya1301/feature-extraction-using-pre-trained-models-for-image-classification-16e6ff43f268\n",
    "2) https://stackoverflow.com/questions/62117707/extract-features-from-pretrained-resnet50-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process image data for feature extraction using CNN\n",
    "input_dir = '../CS610_AML_Group_Project/resized_images'\n",
    "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])]) #mean and std based on ImageNet - normalise image data closer to normal distribution\n",
    "img_dataset = datasets.ImageFolder(input_dir, transform=img_transform)\n",
    "data_loader = DataLoader(img_dataset, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for CNN feature extraction\n",
    "def cnn_feature_extract(cnn_feature_extractor, data_loader):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    #prepare cnn model to use for feature extraction\n",
    "    cnn_feature_extractor.eval()\n",
    "    cnn_feature_extractor.fc = torch.nn.Identity() #replace fully connected layer of pretrained cnn with Identity layer\n",
    "    for para in cnn_feature_extractor.parameters():\n",
    "        para.requires_grad = False #freeze weights\n",
    "    #feature extraction\n",
    "    features_list, labels_list = [], []\n",
    "    cnn_feature_extractor.to(device)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            feature = cnn_feature_extractor(images)\n",
    "            feature = feature.view(feature.size(0),-1) #flatten into (n_samples, n_features) for non-CNN models\n",
    "            #convert tensors into numpy for fitting into non-CNN models and add into lists\n",
    "            features_list.append(feature.cpu().numpy())\n",
    "            labels_list.append(labels.numpy())\n",
    "\n",
    "    return cnn_feature_extractor, np.vstack(features_list), np.hstack(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise and extract features using CNN feature extractor\n",
    "weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "resnet50_extractor = models.resnet50(weights=weights)\n",
    "resnet50_extractor, X, y = cnn_feature_extract(resnet50_extractor, data_loader) #X = features, y =labels\n",
    "#no need labelling as the numpy array is generated from the data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 5184\n",
      "Number of Labels: 50\n",
      "Label Distribution:\n",
      "36    120\n",
      "18    120\n",
      "29    120\n",
      "13    120\n",
      "7     120\n",
      "15    120\n",
      "16    120\n",
      "26    120\n",
      "0     120\n",
      "37    120\n",
      "33    119\n",
      "2     119\n",
      "45    119\n",
      "28    119\n",
      "5     118\n",
      "21    118\n",
      "43    118\n",
      "48    118\n",
      "20    118\n",
      "10    118\n",
      "42    118\n",
      "39    118\n",
      "41    118\n",
      "49    116\n",
      "46     92\n",
      "19     92\n",
      "3      92\n",
      "24     92\n",
      "9      92\n",
      "1      92\n",
      "4      92\n",
      "30     92\n",
      "31     92\n",
      "35     92\n",
      "40     92\n",
      "38     92\n",
      "32     92\n",
      "6      91\n",
      "11     91\n",
      "23     91\n",
      "12     91\n",
      "17     91\n",
      "44     91\n",
      "22     90\n",
      "14     87\n",
      "47     87\n",
      "34     86\n",
      "27     85\n",
      "25     80\n",
      "8      73\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#CNN training and test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)\n",
    "x_train = pd.DataFrame(x_train, dtype=np.float32)\n",
    "y_train = pd.Series(y_train, dtype=np.int32)\n",
    "x_test = pd.DataFrame(x_test, dtype=np.float32)\n",
    "y_test = pd.Series(y_test, dtype=np.int32)\n",
    "#same as original flow\n",
    "print(\"Number of Samples:\", len(y_train))\n",
    "print(\"Number of Labels:\", len(np.unique(y_train)))\n",
    "counts = y_train.value_counts()\n",
    "print(\"Label Distribution:\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) RandomForestClassifier - feature extraction by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Randomized search tuning\u001b[39;00m\n\u001b[32m     24\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m     25\u001b[39m     base_model,\n\u001b[32m     26\u001b[39m     param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     34\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# End timing\u001b[39;00m\n\u001b[32m     38\u001b[39m end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "skip_train = False\n",
    "\n",
    "if skip_train:\n",
    "    # Import previous model\n",
    "    print(\"Training skipped, importing model trained previously...\")\n",
    "    print(\"Fitted 3 folds for each of 30 candidates, totalling 30 fits\")\n",
    "    with open('model_bank/best_cnn_rf_model.pkl', 'rb') as file:\n",
    "        best_cnn_rf = pickle.load(file)\n",
    "\n",
    "else:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Base model\n",
    "    base_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Hyperparameters\n",
    "    param_dist = {\n",
    "        'n_estimators': [50, 100, 150, 200],\n",
    "        'max_depth': [10, 20, 30, 40],\n",
    "        'max_features': ['sqrt', 'log2', 0.5, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    # Randomized search tuning\n",
    "    random_search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_dist,\n",
    "        n_iter=10,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        error_score='raise',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(x_train, y_train)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_train:\n",
    "    print(\"Training skipped, printing model trained previously...\\n\")\n",
    "    print(\"Best Parameters: {'n_estimators': 150, 'max_features': 'sqrt', 'max_depth': 20}\")\n",
    "    print(\"Best Accuracy: 0.719473\")\n",
    "    training_time = 87.56\n",
    "else:\n",
    "    best_cnn_rf = random_search.best_estimator_\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "    print(f\"Best Accuracy: {random_search.best_score_:.6f}\")\n",
    "    training_time = round(training_time / 60, 2)\n",
    "print(f\"Total Training Time: {training_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_train_pred = best_cnn_rf.predict(x_train)\n",
    "y_test_pred = best_cnn_rf.predict(x_test)\n",
    "\n",
    "# Function to save metrics\n",
    "metrics = {\"Metric\": [], \"Average Type\": [], \"Train\": [], \"Test\": []}\n",
    "def add_metric(name, avg_type, train_value, test_value):\n",
    "    metrics[\"Metric\"].append(name)\n",
    "    metrics[\"Average Type\"].append(avg_type)\n",
    "    metrics[\"Train\"].append(train_value)\n",
    "    metrics[\"Test\"].append(test_value)\n",
    "\n",
    "# Training time\n",
    "add_metric(\"Training time (minutes)\", \"N/A\", training_time, \"N/A\")\n",
    "\n",
    "# Accuracy\n",
    "add_metric(\"Accuracy\", \"N/A\",\n",
    "           accuracy_score(y_train, y_train_pred),\n",
    "           accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Precision\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Precision\", avg,\n",
    "               precision_score(y_train, y_train_pred, average=avg),\n",
    "               precision_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# Recall\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Recall\", avg,\n",
    "               recall_score(y_train, y_train_pred, average=avg),\n",
    "               recall_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# F0.5-Score \n",
    "beta = 0.5 # mis-labelled sneakers are more costly than missing labels\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(f\"F{beta}-Score\", avg,\n",
    "               fbeta_score(y_train, y_train_pred, beta=beta, average=avg),\n",
    "               fbeta_score(y_test, y_test_pred, beta=beta, average=avg))\n",
    "\n",
    "# Display metrics\n",
    "cnn_rf_metrics = pd.DataFrame(metrics)\n",
    "pd.set_option('display.precision', 6)\n",
    "display(cnn_rf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = True\n",
    "\n",
    "if not export:\n",
    "    print(\"Model not exported\")\n",
    "else:\n",
    "    model_bank_dir = '../CS610_AML_Group_Project/model_bank'\n",
    "    os.makedirs(model_bank_dir, exist_ok=True)\n",
    "    model_filename_pickle = 'best_cnn_rf_model.pkl'\n",
    "    model_path = os.path.join(model_bank_dir, model_filename_pickle)\n",
    "    with open(model_path, 'wb') as file: \n",
    "        pickle.dump(best_cnn_rf, file)\n",
    "    print(f\"Model Saved Successfully {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) KNNClassifier - feature extraction by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "skip_train = False\n",
    "\n",
    "if skip_train:\n",
    "    # Import previous model\n",
    "    print(\"Training skipped, importing model trained previously...\")\n",
    "    print(\"Fitted 3 folds for each of 10 candidates, totalling 30 fits\")\n",
    "    with open('model_bank/best_cnn_knn_model.pkl', 'rb') as file:\n",
    "        best_cnn_knn = pickle.load(file)\n",
    "\n",
    "else:\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Base model\n",
    "    base_model = KNeighborsClassifier()\n",
    "\n",
    "    # Hyperparameters\n",
    "    param_dist = {\n",
    "        'n_neighbors': randint(1, 30),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'cosine']\n",
    "    }\n",
    "\n",
    "    # Randomized search tuning\n",
    "    random_search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_dist,\n",
    "        n_iter=10,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        error_score='raise',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(x_train, y_train)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "Best Accuracy: 0.302083\n",
      "Total Training Time: 0.22 minutes\n"
     ]
    }
   ],
   "source": [
    "if skip_train:\n",
    "    print(\"Training skipped, printing model trained previously...\\n\")\n",
    "    print(\"Best Parameters: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\")\n",
    "    print(\"Best Accuracy: 0.896123\")\n",
    "    training_time = 3.96\n",
    "else:\n",
    "    best_cnn_knn = random_search.best_estimator_\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "    print(f\"Best Accuracy: {random_search.best_score_:.6f}\")\n",
    "    training_time = round(training_time / 60, 2)\n",
    "print(f\"Total Training Time: {training_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Average Type</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training time (minutes)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.367284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.997988</td>\n",
       "      <td>0.389494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.367284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.998176</td>\n",
       "      <td>0.393255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.361929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.367284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recall</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.367284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.997929</td>\n",
       "      <td>0.37711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>micro</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.367284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F0.5-Score</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>0.381005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric Average Type     Train      Test\n",
       "0   Training time (minutes)          N/A  0.220000       N/A\n",
       "1                  Accuracy          N/A  0.998071  0.367284\n",
       "2                 Precision        macro  0.997988  0.389494\n",
       "3                 Precision        micro  0.998071  0.367284\n",
       "4                 Precision     weighted  0.998176  0.393255\n",
       "5                    Recall        macro  0.997819  0.361929\n",
       "6                    Recall        micro  0.998071  0.367284\n",
       "7                    Recall     weighted  0.998071  0.367284\n",
       "8                F0.5-Score        macro  0.997929   0.37711\n",
       "9                F0.5-Score        micro  0.998071  0.367284\n",
       "10               F0.5-Score     weighted  0.998133  0.381005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict\n",
    "y_train_pred = best_cnn_knn.predict(x_train)\n",
    "y_test_pred = best_cnn_knn.predict(x_test)\n",
    "\n",
    "# Function to save metrics\n",
    "metrics = {\"Metric\": [], \"Average Type\": [], \"Train\": [], \"Test\": []}\n",
    "def add_metric(name, avg_type, train_value, test_value):\n",
    "    metrics[\"Metric\"].append(name)\n",
    "    metrics[\"Average Type\"].append(avg_type)\n",
    "    metrics[\"Train\"].append(train_value)\n",
    "    metrics[\"Test\"].append(test_value)\n",
    "\n",
    "# Training time\n",
    "add_metric(\"Training time (minutes)\", \"N/A\", training_time, \"N/A\")\n",
    "\n",
    "# Accuracy\n",
    "add_metric(\"Accuracy\", \"N/A\",\n",
    "           accuracy_score(y_train, y_train_pred),\n",
    "           accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Precision\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Precision\", avg,\n",
    "               precision_score(y_train, y_train_pred, average=avg),\n",
    "               precision_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# Recall\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Recall\", avg,\n",
    "               recall_score(y_train, y_train_pred, average=avg),\n",
    "               recall_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# F0.5-Score \n",
    "beta = 0.5 # mis-labelled sneakers are more costly than missing labels\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(f\"F{beta}-Score\", avg,\n",
    "               fbeta_score(y_train, y_train_pred, beta=beta, average=avg),\n",
    "               fbeta_score(y_test, y_test_pred, beta=beta, average=avg))\n",
    "\n",
    "# Display metrics\n",
    "cnn_knn_metrics = pd.DataFrame(metrics)\n",
    "pd.set_option('display.precision', 6)\n",
    "display(cnn_knn_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully ../CS610_AML_Group_Project/model_bank\\best_cnn_knn_model.pkl\n"
     ]
    }
   ],
   "source": [
    "export = True\n",
    "\n",
    "if not export:\n",
    "    print(\"Model not exported\")\n",
    "else:\n",
    "    model_bank_dir = '../CS610_AML_Group_Project/model_bank'\n",
    "    os.makedirs(model_bank_dir, exist_ok=True)\n",
    "    model_filename_pickle = 'best_cnn_knn_model.pkl'\n",
    "    model_path = os.path.join(model_bank_dir, model_filename_pickle)\n",
    "    with open(model_path, 'wb') as file: \n",
    "        pickle.dump(best_cnn_knn, file)\n",
    "    print(f\"Model Saved Successfully {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) XGBoostClassifier - feature extraction by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_train = False\n",
    "\n",
    "if skip_train:\n",
    "    # Import previous model\n",
    "    print(\"Training skipped, importing model trained previously...\")\n",
    "    print(\"Fitted 3 folds for each of 30 candidates, totalling 30 fits\")\n",
    "    with open('model_bank/best_cnn_xgb_model.pkl', 'rb') as file:\n",
    "        best_cnn_xgb = pickle.load(file)\n",
    "\n",
    "else:\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Balance class weights\n",
    "    sample_weights = compute_sample_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        y=y_train\n",
    "    )\n",
    "\n",
    "    # Base model\n",
    "    base_model = xgb.XGBClassifier(\n",
    "        device=\"cuda\",\n",
    "        tree_method=\"hist\",\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=len(np.unique(y_train)),\n",
    "        eval_metric=['merror','mlogloss'],\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Hyperparameters\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(50, 500),\n",
    "        'max_depth': randint(3, 12),\n",
    "        'learning_rate': uniform(0.01, 0.19),  # range: 0.01 to 0.2\n",
    "        'subsample': uniform(0.7, 0.3),        # range: 0.7 to 1.0\n",
    "        'colsample_bytree': uniform(0.7, 0.3)  # range: 0.7 to 1.0\n",
    "    }\n",
    "\n",
    "    # Randomized search tuning\n",
    "    random_search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_dist,\n",
    "        n_iter=10,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        error_score='raise',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(\n",
    "        x_train, y_train,\n",
    "        sample_weight = sample_weights)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_train:\n",
    "    print(\"Training skipped, printing model trained previously...\\n\")\n",
    "    print(\"Best Parameters: {'colsample_bytree': 0.7195154778955838, 'learning_rate': 0.19028825207813332, 'max_depth': 4, 'n_estimators': 314, 'subsample': 0.7047898756660642}\")\n",
    "    print(\"Best Accuracy: 0.796345\")\n",
    "    training_time = 216.38\n",
    "else:\n",
    "    best_cnn_xgb = random_search.best_estimator_\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "    print(f\"Best Accuracy: {random_search.best_score_:.6f}\")\n",
    "    training_time = round(training_time / 60, 2)\n",
    "print(f\"Total Training Time: {training_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_train_pred = best_cnn_xgb.predict(x_train)\n",
    "y_test_pred = best_cnn_xgb.predict(x_test)\n",
    "\n",
    "# Function to save metrics\n",
    "metrics = {\"Metric\": [], \"Average Type\": [], \"Train\": [], \"Test\": []}\n",
    "def add_metric(name, avg_type, train_value, test_value):\n",
    "    metrics[\"Metric\"].append(name)\n",
    "    metrics[\"Average Type\"].append(avg_type)\n",
    "    metrics[\"Train\"].append(train_value)\n",
    "    metrics[\"Test\"].append(test_value)\n",
    "\n",
    "# Training time\n",
    "add_metric(\"Training time (minutes)\", \"N/A\", training_time, \"N/A\")\n",
    "\n",
    "# Accuracy\n",
    "add_metric(\"Accuracy\", \"N/A\",\n",
    "           accuracy_score(y_train, y_train_pred),\n",
    "           accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Precision\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Precision\", avg,\n",
    "               precision_score(y_train, y_train_pred, average=avg),\n",
    "               precision_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# Recall\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Recall\", avg,\n",
    "               recall_score(y_train, y_train_pred, average=avg),\n",
    "               recall_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# F0.5-Score \n",
    "beta = 0.5 # mis-labelled sneakers are more costly than missing labels\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(f\"F{beta}-Score\", avg,\n",
    "               fbeta_score(y_train, y_train_pred, beta=beta, average=avg),\n",
    "               fbeta_score(y_test, y_test_pred, beta=beta, average=avg))\n",
    "\n",
    "# Display metrics\n",
    "cnn_xgb_metrics = pd.DataFrame(metrics)\n",
    "pd.set_option('display.precision', 6)\n",
    "display(cnn_xgb_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = True\n",
    "\n",
    "if not export:\n",
    "    print(\"Model not exported\")\n",
    "else:\n",
    "    model_bank_dir = '../CS610_AML_Group_Project/model_bank'\n",
    "    os.makedirs(model_bank_dir, exist_ok=True)\n",
    "    model_filename_pickle = 'best_cnn_xgb_model.pkl'\n",
    "    model_path = os.path.join(model_bank_dir, model_filename_pickle)\n",
    "    with open(model_path, 'wb') as file: \n",
    "        pickle.dump(best_cnn_xgb, file)\n",
    "    print(f\"Model Saved Successfully {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking is a method that help to improve the overall performance of models as the weakness of a certain models can be compensated by the strengths of other models. Hence, we decided to utilise stacking to improve the overall performance of the model. For this technique, only the CNN-feature extraction method will be used as it has been proven to provide better model performance (in terms of accuracy).\n",
    "<br>\n",
    "<br>\n",
    "Using the CNN extracted feature set and the models earlier in the code, they will be used in this stacking technique to determine if stacking improves the overall performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_train = True\n",
    "\n",
    "if skip_train:\n",
    "    # Import previous model\n",
    "    print(\"Training skipped, importing model trained previously...\")\n",
    "    with open('model_bank/stacked_model_pipeline.pkl', 'rb') as file:\n",
    "        stacking_cf = pickle.load(file)\n",
    "    training_time = 135.15\n",
    "\n",
    "else:\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Stacked model\n",
    "    estimators = [('rcf_model',RandomForestClassifier(n_estimators=150, \n",
    "                                                    max_features=\"sqrt\", \n",
    "                                                    max_depth=20, \n",
    "                                                    random_state=42)),\n",
    "                (\"xgboost\",xgb.XGBClassifier(colsample_bytree=0.7195154778955838, \n",
    "                                            learning_rate= 0.19028825207813332, \n",
    "                                            max_depth= 4, n_estimators= 314, \n",
    "                                            subsample=0.7047898756660642,\n",
    "                                            device=\"cuda\",\n",
    "                                            tree_method=\"hist\", \n",
    "                                            objective=\"multi:softprob\", \n",
    "                                            num_class=len(np.unique(y_train)),\n",
    "                                            eval_metric=['merror','mlogloss'],\n",
    "                                            random_state=42)),\n",
    "                (\"knn\", KNeighborsClassifier(metric= \"euclidean\", \n",
    "                                            n_neighbors= 1, \n",
    "                                            weights=\"distance\"))]\n",
    "\n",
    "    stacking_cf = StackingClassifier(estimators=estimators, \n",
    "                                    final_estimator=LogisticRegression(), \n",
    "                                    cv=3, \n",
    "                                    passthrough=False, \n",
    "                                    verbose=1)\n",
    "\n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    stacking_cf.fit(x_train,y_train)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    training_time = round(training_time / 60, 2)\n",
    "\n",
    "print(f\"Total Training Time: {training_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_train_pred = stacking_cf.predict(x_train)\n",
    "y_test_pred = stacking_cf.predict(x_test)\n",
    "\n",
    "# Function to save metrics\n",
    "metrics = {\"Metric\": [], \"Average Type\": [], \"Train\": [], \"Test\": []}\n",
    "def add_metric(name, avg_type, train_value, test_value):\n",
    "    metrics[\"Metric\"].append(name)\n",
    "    metrics[\"Average Type\"].append(avg_type)\n",
    "    metrics[\"Train\"].append(train_value)\n",
    "    metrics[\"Test\"].append(test_value)\n",
    "\n",
    "# Training time\n",
    "add_metric(\"Training time (minutes)\", \"N/A\", training_time, \"N/A\")\n",
    "\n",
    "# Accuracy\n",
    "add_metric(\"Accuracy\", \"N/A\",\n",
    "           accuracy_score(y_train, y_train_pred),\n",
    "           accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Precision\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Precision\", avg,\n",
    "               precision_score(y_train, y_train_pred, average=avg),\n",
    "               precision_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# Recall\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(\"Recall\", avg,\n",
    "               recall_score(y_train, y_train_pred, average=avg),\n",
    "               recall_score(y_test, y_test_pred, average=avg))\n",
    "\n",
    "# F0.5-Score \n",
    "beta = 0.5 # mis-labelled sneakers are more costly than missing labels\n",
    "for avg in ['macro', 'micro', 'weighted']:\n",
    "    add_metric(f\"F{beta}-Score\", avg,\n",
    "               fbeta_score(y_train, y_train_pred, beta=beta, average=avg),\n",
    "               fbeta_score(y_test, y_test_pred, beta=beta, average=avg))\n",
    "\n",
    "# Display metrics\n",
    "stack_metrics = pd.DataFrame(metrics)\n",
    "pd.set_option('display.precision', 6)\n",
    "display(stack_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = True\n",
    "\n",
    "if not export:\n",
    "    print(\"Model not exported\")\n",
    "else:\n",
    "    model_bank_dir = '../CS610_AML_Group_Project/model_bank'\n",
    "    os.makedirs(model_bank_dir, exist_ok=True)\n",
    "    model_filename_pickle = 'stacked_model_pipeline.pkl'\n",
    "    model_path = os.path.join(model_bank_dir, model_filename_pickle)\n",
    "    with open(model_path, 'wb') as file: \n",
    "        pickle.dump(stacking_cf, file)\n",
    "    print(f\"Model Saved Successfully {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
