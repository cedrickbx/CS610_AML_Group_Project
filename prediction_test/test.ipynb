{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import tqdm\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images\n",
    "def resize_image_in_folder(input_dir, output_dir, size=(224, 224), desc='resizing images'):\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory {input_dir} does not exist. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    supported_formats = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(supported_formats):\n",
    "            img_input_path = os.path.join(input_dir, filename)\n",
    "            img_output_path = os.path.join(output_dir, filename)\n",
    "            try:\n",
    "                img = cv2.imread(img_input_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "                if img is None:\n",
    "                    print(f\"Error loading {img_input_path}\")\n",
    "                    continue\n",
    "                resized_img = cv2.resize(img, size, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "                if img_output_path.lower().endswith(('.jpg', '.jpeg')) and resized_img.shape[-1] == 4:\n",
    "                    resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGRA2BGR)\n",
    "                cv2.imwrite(img_output_path, resized_img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_input_path}: {e}\")\n",
    "# process all folders\n",
    "def batch_resize_images(base_input_dir, base_output_dir, size=(128, 128)):\n",
    "    if not os.path.exists(base_input_dir):\n",
    "        print(f\"Base directory {base_input_dir} does not exist. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(base_output_dir, exist_ok=True) # if output directory does not exist, create it.\n",
    "\n",
    "    for folder in tqdm.tqdm(os.listdir(base_input_dir)):\n",
    "        current_input_subfolder = os.path.join(base_input_dir, folder)\n",
    "        current_output_subfolder = os.path.join(base_output_dir, folder)\n",
    "\n",
    "        if os.path.isdir(current_input_subfolder):\n",
    "            resize_image_in_folder(current_input_subfolder, current_output_subfolder, size=size)\n",
    "        else:\n",
    "            print(f\"Skipping {current_input_subfolder} as it is not a directory.\")\n",
    "\n",
    "    print(\"Batch resizing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch resizing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dir = r'D:\\Github\\CS610_AML_Group_Project\\prediction_test\\test_image\\orginal_data'\n",
    "output_dir = r'D:\\Github\\CS610_AML_Group_Project\\prediction_test\\test_image\\resized_data'\n",
    "batch_resize_images(input_dir, output_dir, size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Process image data for feature extraction using CNN\n",
    "input_dir = r'D:\\Github\\CS610_AML_Group_Project\\prediction_test\\test_image\\resized_data'\n",
    "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])]) #mean and std based on ImageNet - normalise image data closer to normal distribution\n",
    "img_dataset = datasets.ImageFolder(input_dir, transform=img_transform)\n",
    "data_loader = DataLoader(img_dataset, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for CNN feature extraction\n",
    "def cnn_feature_extract(cnn_feature_extractor, data_loader):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    #prepare cnn model to use for feature extraction\n",
    "    cnn_feature_extractor.eval()\n",
    "    cnn_feature_extractor.fc = torch.nn.Identity() #replace fully connected layer of pretrained cnn with Identity layer\n",
    "    for para in cnn_feature_extractor.parameters():\n",
    "        para.requires_grad = False #freeze weights\n",
    "    #feature extraction\n",
    "    features_list, labels_list = [], []\n",
    "    cnn_feature_extractor.to(device)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            feature = cnn_feature_extractor(images)\n",
    "            feature = feature.view(feature.size(0),-1) #flatten into (n_samples, n_features) for non-CNN models\n",
    "            #convert tensors into numpy for fitting into non-CNN models and add into lists\n",
    "            features_list.append(feature.cpu().numpy())\n",
    "            labels_list.append(labels.numpy())\n",
    "\n",
    "    return cnn_feature_extractor, np.vstack(features_list), np.hstack(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "        'adidas_forum_high', 'adidas_forum_low', 'adidas_gazelle', 'adidas_nmd_r1',\n",
    "        'adidas_samba', 'adidas_stan_smith', 'adidas_superstar', 'adidas_ultraboost',\n",
    "        'asics_gel-lyte_iii', 'converse_chuck_70_high', 'converse_chuck_70_low',\n",
    "        'converse_chuck_taylor_all-star_high', 'converse_chuck_taylor_all-star_low',\n",
    "        'converse_one_star', 'new_balance_327', 'new_balance_550', 'new_balance_574',\n",
    "        'new_balance_990', 'new_balance_992', 'nike_air_force_1_high',\n",
    "        'nike_air_force_1_low', 'nike_air_force_1_mid', 'nike_air_jordan_1_high',\n",
    "        'nike_air_jordan_1_low', 'nike_air_jordan_11', 'nike_air_jordan_3',\n",
    "        'nike_air_jordan_4', 'nike_air_max_1', 'nike_air_max_270', 'nike_air_max_90',\n",
    "        'nike_air_max_95', 'nike_air_max_97', 'nike_air_max_plus_(tn)',\n",
    "        'nike_air_vapormax_flyknit', 'nike_air_vapormax_plus', 'nike_blazer_mid_77',\n",
    "        'nike_cortez', 'nike_dunk_high', 'nike_dunk_low', 'puma_suede_classic',\n",
    "        'reebok_classic_leather', 'reebok_club_c_85', 'salomon_xt-6',\n",
    "        'vans_authentic', 'vans_old_skool', 'vans_sk8-hi', 'vans_slip-on_checkerboard',\n",
    "        'yeezy_700_wave_runner', 'yeezy_boost_350_v2', 'yeezy_slide'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "resnet50_extractor = models.resnet50(weights=weights)\n",
    "resnet50_extractor, X, _ = cnn_feature_extract(resnet50_extractor, data_loader) #X = features, y =labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nike_air_force_1_low\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "import pickle\n",
    "with open('D:/Github/CS610_AML_Group_Project/model_bank/best_cnn_knn_model.pkl', 'rb') as f:\n",
    "    best_cnn_knn_model = pickle.load(f)\n",
    "\n",
    "# load data\n",
    "\n",
    "# predict\n",
    "predictions = best_cnn_knn_model.predict(X)\n",
    "\n",
    "print(class_names[predictions[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
