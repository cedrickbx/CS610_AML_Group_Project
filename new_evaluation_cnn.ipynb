{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "84881561",
      "metadata": {
        "id": "84881561"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "import shutil\n",
        "import tqdm\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if cuda is available to use\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device, \"is used\")"
      ],
      "metadata": {
        "id": "i7oG2yqaUnvP"
      },
      "id": "i7oG2yqaUnvP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Process image data for feature extraction using CNN\n",
        "input_dir = '../CS610_AML_Group_Project/resized_images'\n",
        "full_set = datasets.ImageFolder(input_dir)"
      ],
      "metadata": {
        "id": "iWL9DdCGU0Bv"
      },
      "id": "iWL9DdCGU0Bv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get classes from directory\n",
        "num_classes = len(full_set.classes)\n",
        "class_names = full_set.classes\n",
        "print(\"Number of classes (Full Set):\", num_classes,\"\\n\", full_set.classes)"
      ],
      "metadata": {
        "id": "TrrKJNntU8LT"
      },
      "id": "TrrKJNntU8LT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = torch.load(\"/content/CS610_AML_Group_Project/model_bank/best_cnn_resnet50.pth\")\n",
        "cnn_model = models.resnet50(pretrained=True)\n",
        "cnn_model.fc = nn.Linear(cnn_model.fc.in_features, len(class_names))\n",
        "cnn_model = cnn_model.to(device)\n",
        "cnn_model.load_state_dict(best_model)"
      ],
      "metadata": {
        "id": "PgYTtJbBSV5c"
      },
      "id": "PgYTtJbBSV5c",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "faefa422",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faefa422",
        "outputId": "c7e00d41-ebbc-423a-de75-2abf87b36103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data processing done\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees = 15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast = 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],std=[0.229,0.224,0.225]) #ImageNet\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "     transforms.Normalize([0.485,0.456,0.406],std=[0.229,0.224,0.225]) #ImageNet\n",
        "])\n",
        "\n",
        "train_size = int(0.7*len(full_set))\n",
        "val_size = int(0.2*len(full_set))\n",
        "test_size = len(full_set)-train_size-val_size\n",
        "split_datasets = random_split(\n",
        "    full_set,\n",
        "    [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "train_indices = split_datasets[0].indices\n",
        "val_indices = split_datasets[1].indices\n",
        "test_indices = split_datasets[2].indices\n",
        "\n",
        "class CustomSubsetWithTransform(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, indices, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        original_idx = self.indices[idx]\n",
        "        img, label = self.dataset[original_idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "train_img_dataset = CustomSubsetWithTransform(full_set, train_indices, train_transform)\n",
        "val_img_dataset = CustomSubsetWithTransform(full_set, val_indices, val_test_transform)\n",
        "test_img_dataset = CustomSubsetWithTransform(full_set, test_indices, val_test_transform)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_img_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_img_dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_img_dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "print(\"Data processing done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e32fb0b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e32fb0b2",
        "outputId": "71126574-f903-4255-efc2-3ab3f40597e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes (Full Set): 50 \n",
            " ['adidas_forum_high', 'adidas_forum_low', 'adidas_gazelle', 'adidas_nmd_r1', 'adidas_samba', 'adidas_stan_smith', 'adidas_superstar', 'adidas_ultraboost', 'asics_gel-lyte_iii', 'converse_chuck_70_high', 'converse_chuck_70_low', 'converse_chuck_taylor_all-star_high', 'converse_chuck_taylor_all-star_low', 'converse_one_star', 'new_balance_327', 'new_balance_550', 'new_balance_574', 'new_balance_990', 'new_balance_992', 'nike_air_force_1_high', 'nike_air_force_1_low', 'nike_air_force_1_mid', 'nike_air_jordan_11', 'nike_air_jordan_1_high', 'nike_air_jordan_1_low', 'nike_air_jordan_3', 'nike_air_jordan_4', 'nike_air_max_1', 'nike_air_max_270', 'nike_air_max_90', 'nike_air_max_95', 'nike_air_max_97', 'nike_air_max_plus_(tn)', 'nike_air_vapormax_flyknit', 'nike_air_vapormax_plus', 'nike_blazer_mid_77', 'nike_cortez', 'nike_dunk_high', 'nike_dunk_low', 'puma_suede_classic', 'reebok_classic_leather', 'reebok_club_c_85', 'salomon_xt-6', 'vans_authentic', 'vans_old_skool', 'vans_sk8-hi', 'vans_slip-on_checkerboard', 'yeezy_700_wave_runner', 'yeezy_boost_350_v2', 'yeezy_slide']\n"
          ]
        }
      ],
      "source": [
        "#get classes from directory\n",
        "num_classes = len(full_set.classes)\n",
        "class_names = full_set.classes\n",
        "print(\"Number of classes (Full Set):\", num_classes,\"\\n\", full_set.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a57e53d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a57e53d5",
        "outputId": "e7927640-70fd-4381-86db-8d74309a5c7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#load best cnn_model\n",
        "best_model = torch.load(\"/content/CS610_AML_Group_Project/model_bank/best_cnn_resnet50.pth\")\n",
        "cnn_model = models.resnet50(pretrained=True)\n",
        "cnn_model.fc = nn.Linear(cnn_model.fc.in_features, len(class_names))\n",
        "cnn_model = cnn_model.to(device)\n",
        "cnn_model.load_state_dict(best_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create dictionary to store metrics\n",
        "train_holder = {}\n",
        "train_holder['y_true'], train_holder['y_hat'] = [], []\n",
        "#start evaluation of model\n",
        "cnn_model.eval()\n",
        "train_corrects = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = cnn_model(images)\n",
        "        _, train_preds = torch.max(output, 1)\n",
        "        train_corrects += (train_preds == labels).sum().item()\n",
        "        train_holder['y_true'].extend(list(labels.cpu().detach().numpy()))\n",
        "        train_holder['y_hat'].extend(list(train_preds.cpu().detach().numpy()))\n",
        "\n",
        "\n",
        "train_y_true_all = train_holder['y_true']\n",
        "train_y_pred_all = train_holder['y_hat']\n",
        "train_acc = train_corrects / len(train_loader.dataset)\n",
        "train_precision = precision_score(train_y_true_all, train_y_pred_all, average='macro')\n",
        "train_recall = recall_score(train_y_true_all, train_y_pred_all, average='macro')\n",
        "train_fbeta = fbeta_score(train_y_true_all, train_y_pred_all, beta=0.5,average='macro')\n",
        "train_class_report = classification_report(train_y_true_all, train_y_pred_all)"
      ],
      "metadata": {
        "id": "WoubekOyGWUM"
      },
      "id": "WoubekOyGWUM",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ae34773f",
      "metadata": {
        "id": "ae34773f"
      },
      "outputs": [],
      "source": [
        "#create dictionary to store metrics\n",
        "test_holder = {}\n",
        "test_holder['y_true'], test_holder['y_hat'] = [], []\n",
        "#start evaluation of model\n",
        "cnn_model.eval()\n",
        "test_corrects = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = cnn_model(images)\n",
        "        _, test_preds = torch.max(output, 1)\n",
        "        test_corrects += (test_preds == labels).sum().item()\n",
        "        test_holder['y_true'].extend(list(labels.cpu().detach().numpy()))\n",
        "        test_holder['y_hat'].extend(list(test_preds.cpu().detach().numpy()))\n",
        "\n",
        "\n",
        "test_y_true_all = test_holder['y_true']\n",
        "test_y_pred_all = test_holder['y_hat']\n",
        "test_acc = test_corrects / len(test_loader.dataset)\n",
        "test_precision = precision_score(test_y_true_all, test_y_pred_all, average='macro')\n",
        "test_recall = recall_score(test_y_true_all, test_y_pred_all, average='macro')\n",
        "test_fbeta = fbeta_score(test_y_true_all, test_y_pred_all, beta=0.5,average='macro')\n",
        "test_class_report = classification_report(test_y_true_all, test_y_pred_all)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create dictionary to store metrics\n",
        "val_holder = {}\n",
        "val_holder['y_true'], val_holder['y_hat'] = [], []\n",
        "#start evaluation of model\n",
        "cnn_model.eval()\n",
        "val_corrects = 0\n",
        "with torch.no_grad():\n",
        "    for data in val_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = cnn_model(images)\n",
        "        _, val_preds = torch.max(output, 1)\n",
        "        val_corrects += (val_preds == labels).sum().item()\n",
        "        val_holder['y_true'].extend(list(labels.cpu().detach().numpy()))\n",
        "        val_holder['y_hat'].extend(list(val_preds.cpu().detach().numpy()))\n",
        "\n",
        "\n",
        "val_y_true_all = val_holder['y_true']\n",
        "val_y_pred_all = val_holder['y_hat']\n",
        "val_acc = val_corrects / len(val_loader.dataset)\n",
        "val_precision = precision_score(val_y_true_all, val_y_pred_all, average='macro')\n",
        "val_recall = recall_score(val_y_true_all, val_y_pred_all, average='macro')\n",
        "val_fbeta = fbeta_score(val_y_true_all, val_y_pred_all, beta=0.5,average='macro')\n",
        "val_class_report = classification_report(val_y_true_all, val_y_pred_all)"
      ],
      "metadata": {
        "id": "Rs_5IPg_G4hT"
      },
      "id": "Rs_5IPg_G4hT",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*5 + 'Training Metrics'+'='*5)\n",
        "print(f\"Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Precision: {train_precision:.4f}\")\n",
        "print(f\"Recall: {train_recall:.4f}\")\n",
        "print(f\"F0.5-Score: {train_fbeta:.4f}\")\n",
        "\n",
        "print(\"=\"*5 + 'Validation Metrics'+'='*2)\n",
        "print(f\"Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Precision: {val_precision:.4f}\")\n",
        "print(f\"Recall: {val_recall:.4f}\")\n",
        "print(f\"F0.5-Score: {val_fbeta:.4f}\")\n",
        "\n",
        "print(\"=\"*5 + 'Testing Metrics'+'='*5)\n",
        "print(f\"Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "print(f\"F0.5-Score: {test_fbeta:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhYwdMVyHVwy",
        "outputId": "571cad64-bcce-40e1-9f3d-f18d4d47abe0"
      },
      "id": "hhYwdMVyHVwy",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Training Metrics=====\n",
            "Accuracy: 0.9843\n",
            "Precision: 0.9843\n",
            "Recall: 0.9842\n",
            "F0.5-Score: 0.9841\n",
            "=====Validation Metrics==\n",
            "Accuracy: 0.8194\n",
            "Precision: 0.8335\n",
            "Recall: 0.8183\n",
            "F0.5-Score: 0.8247\n",
            "=====Testing Metrics=====\n",
            "Accuracy: 0.7901\n",
            "Precision: 0.8087\n",
            "Recall: 0.7859\n",
            "F0.5-Score: 0.7969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "peUN79LJHh2L"
      },
      "id": "peUN79LJHh2L",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}